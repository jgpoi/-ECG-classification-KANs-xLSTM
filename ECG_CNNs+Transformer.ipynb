{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12388094,"sourceType":"datasetVersion","datasetId":7811510}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"7a3d4edc-4ad6-40ef-9c06-99c320a50b46","cell_type":"code","source":"#### -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Jan  8 13:58:40 2025\n\n@author: 29551\n\"\"\"\n!pip install ptflops\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score, confusion_matrix, recall_score, precision_score\nimport matplotlib.pyplot as plt\nfrom ptflops import get_model_complexity_info\nimport time\n# è¯»å–æ•°æ®\ndata = pd.read_csv('/kaggle/input/mitbih/ECG_data.csv')\n\n# æå–ä¿¡å·å’Œæ ‡ç­¾\nsignals = data['Signal'].apply(lambda x: np.fromstring(x[1:-1], sep=',')).values\nlabels = data['Label'].values\n\n# è½¬æ¢ä¿¡å·ä¸º NumPy æ•°ç»„\nsignals = np.array([np.array(signal) for signal in signals])\n\n# è½¬æ¢ä¿¡å·ä¸º PyTorch å¼ é‡\nsignals = torch.tensor(signals, dtype=torch.float32).unsqueeze(1)  # å¢žåŠ é€šé“ç»´åº¦ (N, 1, 300)\n\n# æ ‡ç­¾ç¼–ç \nlabel_encoder = LabelEncoder()\nlabels_encoded = label_encoder.fit_transform(labels)\n\n\n# åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•é›†\nX_train, X_temp, y_train, y_temp = train_test_split(\n    signals, labels_encoded, test_size=0.3, random_state=42, stratify=labels_encoded)\n\n# ç¬¬äºŒæ­¥ï¼šå°†ä¸´æ—¶é›†ä¸­çš„ 2/3 è®¾ä¸ºéªŒè¯é›†ï¼ˆ20%ï¼‰ï¼Œ1/3 è®¾ä¸ºæµ‹è¯•é›†ï¼ˆ10%ï¼‰\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp, test_size=1/3, random_state=42, stratify=y_temp)\n\n# è½¬æ¢ä¸ºTensor\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.long)\ny_val_tensor = torch.tensor(y_val, dtype=torch.long)\ny_test_tensor = torch.tensor(y_test, dtype=torch.long)\n\n# åˆ›å»ºDataLoader\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n\n# Focal Loss å®šä¹‰\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2.0, alpha=0.25):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n\n    def forward(self, logits, targets):\n        ce_loss = nn.CrossEntropyLoss(reduction='none')(logits, targets)\n        pt = torch.exp(-ce_loss)  # è®¡ç®— p_t\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        return focal_loss.mean()\n\n\n\n# Transformer æ¨¡å—å®šä¹‰\nclass TransformerBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n        super(TransformerBlock, self).__init__()\n        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout)\n        self.feed_forward = nn.Sequential(\n            nn.Linear(embed_dim, ff_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(ff_dim, embed_dim)\n        )\n        self.layernorm1 = nn.LayerNorm(embed_dim)\n        self.layernorm2 = nn.LayerNorm(embed_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # Self-attention\n        attn_output, _ = self.attention(x, x, x)\n        x = self.layernorm1(x + self.dropout(attn_output))  # æ®‹å·®è¿žæŽ¥ + LayerNorm\n\n        # Feed-forward\n        ff_output = self.feed_forward(x)\n        x = self.layernorm2(x + self.dropout(ff_output))  # æ®‹å·®è¿žæŽ¥ + LayerNorm\n        return x\n\n# åˆ†ç±»æ¨¡åž‹å®šä¹‰\nclass CNNTransformerModel(nn.Module):\n    def __init__(self, input_length, num_classes, embed_dim=128, num_heads=4, ff_dim=256, num_layers=2, dropout=0.2):\n        super(CNNTransformerModel, self).__init__()\n        # CNN ç‰¹å¾æå–æ¨¡å—\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(32, 128, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv1d(128, 64, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n        \n        # Transformer æ¨¡å—\n        self.embedding = nn.Linear(64, embed_dim)  # å°† CNN è¾“å‡ºç‰¹å¾æ˜ å°„åˆ° Transformer è¾“å…¥\n        self.transformer_blocks = nn.ModuleList([\n            TransformerBlock(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_layers)\n        ])\n\n        # åˆ†ç±»å±‚\n        self.fc = nn.Sequential(\n            nn.Linear(embed_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        # CNN æ¨¡å—\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.pool(x)  # è¾“å‡ºç»´åº¦: (batch_size, channels, seq_length)\n        x = self.conv3(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        # è½¬ç½®ä»¥é€‚é… Transformer è¾“å…¥\n        x = x.permute(0, 2, 1)  # è½¬æ¢ä¸º (batch_size, seq_length, features)\n        x = self.embedding(x)   # æ˜ å°„åˆ° Transformer åµŒå…¥ç»´åº¦ (batch_size, seq_length, embed_dim)\n\n        # Transformer æ¨¡å—\n        for transformer in self.transformer_blocks:\n            x = transformer(x)\n\n        # åˆ†ç±»æ¨¡å—\n        x = x.mean(dim=1)  # å…¨å±€å¹³å‡æ± åŒ– (batch_size, embed_dim)\n        outputs = self.fc(x)  # å…¨è¿žæŽ¥å±‚\n        return outputs\n\n# æ¨¡åž‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\ninput_length = 300\nnum_classes =5\nmodel = CNNTransformerModel(input_length=input_length, num_classes=num_classes)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n# é€‰æ‹©è®¾å¤‡\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# å®šä¹‰æŸå¤±å‡½æ•°\ncriterion = FocalLoss()  # ä½¿ç”¨ Focal Loss\n\ndef compute_test_metrics(model, data_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    all_targets = []\n    all_predictions = []\n    \n    start_time = time.time()  # âœ… å¼€å§‹è®¡æ—¶\n    with torch.no_grad():\n        for data, target in data_loader:\n            data = data.to(device)       # input to GPU\n            target = target.to(device) \n            output = model(data)\n            _, predicted = torch.max(output, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n            all_targets.extend(target.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n            \n    end_time = time.time()  # âœ… ç»“æŸè®¡æ—¶\n    elapsed_time = end_time - start_time\n    accuracy = 100 * correct / total\n    f1 = f1_score(all_targets, all_predictions, average='weighted')\n    sensitivity = recall_score(all_targets, all_predictions, average='weighted')\n    precision = precision_score(all_targets, all_predictions, average='weighted')\n\n    conf_matrix = confusion_matrix(all_targets, all_predictions)\n    tn = conf_matrix.sum() - conf_matrix.sum(axis=0) - conf_matrix.sum(axis=1) + np.diagonal(conf_matrix)\n    fp = conf_matrix.sum(axis=0) - np.diagonal(conf_matrix)\n    specificity_per_class = tn / (tn + fp + 1e-6)\n    samples_per_class = conf_matrix.sum(axis=1)\n    total_samples = np.sum(samples_per_class)\n    specificity = np.sum((samples_per_class / total_samples) * specificity_per_class)\n\n    return accuracy, f1, sensitivity, precision, specificity, conf_matrix,elapsed_time\n\ndef plot_acc_loss(history):\n    epochs = range(1, len(history['train_acc']) + 1)\n\n    fig, ax1 = plt.subplots(figsize=(10, 6))\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Accuracy (%)', color='tab:blue')\n    ax1.plot(epochs, history['train_acc'], label='Train Accuracy', color='tab:blue', linestyle='-')\n    ax1.plot(epochs, history['val_acc'], label='Val Accuracy', color='tab:blue', linestyle='--')\n    ax1.tick_params(axis='y', labelcolor='tab:blue')\n    ax1.set_ylim(90,100)\n    ax1.grid(-True)\n    \n    ax2 = ax1.twinx()\n    ax2.set_ylabel('Loss', color='tab:red')\n    ax2.plot(epochs, history['train_loss'], label='Train Loss', color='tab:red', linestyle='-')\n    ax2.plot(epochs, history['val_loss'], label='Val Loss', color='tab:red', linestyle='--')\n    ax2.tick_params(axis='y', labelcolor='tab:red')\n    ax2.set_ylim(0,0.03)\n    lines1, labels1 = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax1.legend(lines1 + lines2, labels1 + labels2, loc='center right')\n\n    plt.title('Accuracy and Loss over Epochs')\n    fig.tight_layout()\n    plt.savefig(\"CNNs+Transformer Accuracy_Loss Dual Axis.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n    plt.show()\n\n\ndef train_and_evaluate(model, train_loader, val_loader, test_loader, criterion, optimizer, num_epochs):\n    history = {\n        'train_acc': [], 'val_acc': [],\n        'train_loss': [], 'val_loss': []\n    }\n    best_val_loss = float('inf')  \n    best_model_path = 'CNNs+Transformer best_model.pth'\n    for epoch in range(num_epochs):\n        # === Training ===\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n\n        for data, target in train_loader:\n            optimizer.zero_grad()\n            data = data.to(device)       # input to GPU\n            target = target.to(device) \n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(output, 1)\n            total_train += target.size(0)\n            correct_train += (predicted == target).sum().item()\n\n        train_loss = running_loss / len(train_loader)\n        train_acc = 100 * correct_train / total_train\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n\n        # === Validation ===\n        model.eval()\n        val_loss = 0.0\n        correct_val = 0\n        total_val = 0\n\n        with torch.no_grad():\n            for data, target in val_loader:\n                data = data.to(device)       # input to GPU\n                target = target.to(device)   # label to GPU (if needed for loss)\n                output = model(data)\n                loss = criterion(output, target)\n                val_loss += loss.item()\n                _, predicted = torch.max(output, 1)\n                total_val += target.size(0)\n                correct_val += (predicted == target).sum().item()\n\n        val_loss /= len(val_loader)\n        val_acc = 100 * correct_val / total_val\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n\n\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n        print(f\"  Train -> Acc: {train_acc:.2f}% | Loss: {train_loss:.4f}\")\n        print(f\"  Val   -> Acc: {val_acc:.2f}% | Loss: {val_loss:.4f}\")\n\n        # === Save Best Model (based on validation loss) ===\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), best_model_path)\n            print(\"  âœ… Best model saved (state_dict).\")\n        else:\n            print(\"  No improvement.\")\n\n    # === é‡æ–°åŠ è½½æœ€ä¼˜æ¨¡åž‹è¿›è¡Œæµ‹è¯• ===\n    model.load_state_dict(torch.load(best_model_path))\n    model.eval()\n\n    # === æµ‹è¯•é›†è¯„ä¼° ===\n    start_time = time.time()\n    test_acc, test_f1, test_sen, test_ppv, test_spe, conf_matrix, test_time = compute_test_metrics(model, test_loader)\n    test_time = time.time() - start_time\n\n    print(\"\\n=== Final Test Set Performance ===\")\n    print(f\"Test Acc: {test_acc:.2f}% | F1: {test_f1:.4f} | Sensitivity: {test_sen:.4f} | \"\n          f\"PPV: {test_ppv:.4f} | Specificity: {test_spe:.4f}\")\n    print(f\"ðŸ•’ Inference Time on Test Set: {test_time:.2f} seconds\")\n\n    # === è®¡ç®—æ¨¡åž‹å‚æ•°é‡å’Œ FLOPs ===\n    print(\"\\n=== Model Complexity ===\")\n    macs, params = get_model_complexity_info(\n        model, input_res=(1,300), as_strings=True,\n        print_per_layer_stat=False, verbose=False\n    )\n    print(f\"ðŸ“Š Params: {params}\")\n    print(f\"ðŸ“Š FLOPs: {macs}\")\n\n    # === ä¿å­˜æ¨¡åž‹ç»“æž„å¤æ‚åº¦ä¿¡æ¯åˆ°æ–‡ä»¶ ===\n    with open(\"CNNs+Transformer_Model_Complexity.txt\", \"w\") as f:\n        f.write(f\"Params: {params}\\nFLOPs: {macs}\\nTest Time: {test_time:.2f} sec\")\n\n    return model, history\n\ntrain_and_evaluate(model, train_loader, val_loader, test_loader, criterion, optimizer, num_epochs=50)     ","metadata":{"ExecutionIndicator":{"show":true},"execution":{"iopub.status.busy":"2025-07-08T12:19:32.895508Z","iopub.execute_input":"2025-07-08T12:19:32.896157Z","iopub.status.idle":"2025-07-08T12:26:49.148896Z","shell.execute_reply.started":"2025-07-08T12:19:32.896128Z","shell.execute_reply":"2025-07-08T12:26:49.147993Z"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ptflops in /usr/local/lib/python3.11/dist-packages (0.7.4)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from ptflops) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->ptflops) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->ptflops) (3.0.2)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/2978058491.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n/tmp/ipykernel_35/2978058491.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n/tmp/ipykernel_35/2978058491.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/50]\n  Train -> Acc: 87.97% | Loss: 0.0502\n  Val   -> Acc: 93.11% | Loss: 0.0263\n  âœ… Best model saved (state_dict).\nEpoch [2/50]\n  Train -> Acc: 93.81% | Loss: 0.0232\n  Val   -> Acc: 94.48% | Loss: 0.0185\n  âœ… Best model saved (state_dict).\nEpoch [3/50]\n  Train -> Acc: 94.76% | Loss: 0.0185\n  Val   -> Acc: 94.94% | Loss: 0.0183\n  âœ… Best model saved (state_dict).\nEpoch [4/50]\n  Train -> Acc: 95.38% | Loss: 0.0160\n  Val   -> Acc: 96.05% | Loss: 0.0136\n  âœ… Best model saved (state_dict).\nEpoch [5/50]\n  Train -> Acc: 95.67% | Loss: 0.0144\n  Val   -> Acc: 96.18% | Loss: 0.0125\n  âœ… Best model saved (state_dict).\nEpoch [6/50]\n  Train -> Acc: 95.97% | Loss: 0.0134\n  Val   -> Acc: 96.91% | Loss: 0.0105\n  âœ… Best model saved (state_dict).\nEpoch [7/50]\n  Train -> Acc: 96.14% | Loss: 0.0123\n  Val   -> Acc: 96.69% | Loss: 0.0113\n  No improvement.\nEpoch [8/50]\n  Train -> Acc: 96.34% | Loss: 0.0120\n  Val   -> Acc: 96.74% | Loss: 0.0116\n  No improvement.\nEpoch [9/50]\n  Train -> Acc: 96.32% | Loss: 0.0118\n  Val   -> Acc: 96.11% | Loss: 0.0120\n  No improvement.\nEpoch [10/50]\n  Train -> Acc: 96.60% | Loss: 0.0111\n  Val   -> Acc: 97.13% | Loss: 0.0100\n  âœ… Best model saved (state_dict).\nEpoch [11/50]\n  Train -> Acc: 96.88% | Loss: 0.0103\n  Val   -> Acc: 97.29% | Loss: 0.0089\n  âœ… Best model saved (state_dict).\nEpoch [12/50]\n  Train -> Acc: 96.91% | Loss: 0.0100\n  Val   -> Acc: 97.20% | Loss: 0.0094\n  No improvement.\nEpoch [13/50]\n  Train -> Acc: 96.94% | Loss: 0.0097\n  Val   -> Acc: 97.36% | Loss: 0.0090\n  No improvement.\nEpoch [14/50]\n  Train -> Acc: 97.13% | Loss: 0.0092\n  Val   -> Acc: 97.43% | Loss: 0.0083\n  âœ… Best model saved (state_dict).\nEpoch [15/50]\n  Train -> Acc: 97.05% | Loss: 0.0091\n  Val   -> Acc: 97.35% | Loss: 0.0089\n  No improvement.\nEpoch [16/50]\n  Train -> Acc: 97.24% | Loss: 0.0087\n  Val   -> Acc: 97.55% | Loss: 0.0084\n  No improvement.\nEpoch [17/50]\n  Train -> Acc: 97.22% | Loss: 0.0086\n  Val   -> Acc: 97.24% | Loss: 0.0100\n  No improvement.\nEpoch [18/50]\n  Train -> Acc: 97.21% | Loss: 0.0086\n  Val   -> Acc: 97.29% | Loss: 0.0094\n  No improvement.\nEpoch [19/50]\n  Train -> Acc: 97.29% | Loss: 0.0082\n  Val   -> Acc: 97.24% | Loss: 0.0095\n  No improvement.\nEpoch [20/50]\n  Train -> Acc: 97.39% | Loss: 0.0079\n  Val   -> Acc: 97.74% | Loss: 0.0078\n  âœ… Best model saved (state_dict).\nEpoch [21/50]\n  Train -> Acc: 97.49% | Loss: 0.0077\n  Val   -> Acc: 97.51% | Loss: 0.0085\n  No improvement.\nEpoch [22/50]\n  Train -> Acc: 97.44% | Loss: 0.0079\n  Val   -> Acc: 97.79% | Loss: 0.0075\n  âœ… Best model saved (state_dict).\nEpoch [23/50]\n  Train -> Acc: 97.54% | Loss: 0.0076\n  Val   -> Acc: 97.67% | Loss: 0.0086\n  No improvement.\nEpoch [24/50]\n  Train -> Acc: 97.51% | Loss: 0.0075\n  Val   -> Acc: 96.96% | Loss: 0.0096\n  No improvement.\nEpoch [25/50]\n  Train -> Acc: 97.54% | Loss: 0.0074\n  Val   -> Acc: 97.68% | Loss: 0.0076\n  No improvement.\nEpoch [26/50]\n  Train -> Acc: 97.62% | Loss: 0.0072\n  Val   -> Acc: 96.98% | Loss: 0.0094\n  No improvement.\nEpoch [27/50]\n  Train -> Acc: 97.62% | Loss: 0.0070\n  Val   -> Acc: 97.69% | Loss: 0.0076\n  No improvement.\nEpoch [28/50]\n  Train -> Acc: 97.65% | Loss: 0.0071\n  Val   -> Acc: 97.75% | Loss: 0.0077\n  No improvement.\nEpoch [29/50]\n  Train -> Acc: 97.73% | Loss: 0.0067\n  Val   -> Acc: 97.82% | Loss: 0.0073\n  âœ… Best model saved (state_dict).\nEpoch [30/50]\n  Train -> Acc: 97.77% | Loss: 0.0066\n  Val   -> Acc: 97.58% | Loss: 0.0084\n  No improvement.\nEpoch [31/50]\n  Train -> Acc: 97.57% | Loss: 0.0070\n  Val   -> Acc: 97.55% | Loss: 0.0079\n  No improvement.\nEpoch [32/50]\n  Train -> Acc: 97.75% | Loss: 0.0067\n  Val   -> Acc: 97.73% | Loss: 0.0076\n  No improvement.\nEpoch [33/50]\n  Train -> Acc: 97.74% | Loss: 0.0067\n  Val   -> Acc: 97.57% | Loss: 0.0076\n  No improvement.\nEpoch [34/50]\n  Train -> Acc: 97.76% | Loss: 0.0064\n  Val   -> Acc: 97.39% | Loss: 0.0083\n  No improvement.\nEpoch [35/50]\n  Train -> Acc: 97.88% | Loss: 0.0062\n  Val   -> Acc: 97.61% | Loss: 0.0078\n  No improvement.\nEpoch [36/50]\n  Train -> Acc: 97.86% | Loss: 0.0062\n  Val   -> Acc: 97.66% | Loss: 0.0077\n  No improvement.\nEpoch [37/50]\n  Train -> Acc: 97.87% | Loss: 0.0061\n  Val   -> Acc: 97.82% | Loss: 0.0078\n  No improvement.\nEpoch [38/50]\n  Train -> Acc: 97.84% | Loss: 0.0063\n  Val   -> Acc: 97.73% | Loss: 0.0075\n  No improvement.\nEpoch [39/50]\n  Train -> Acc: 97.78% | Loss: 0.0062\n  Val   -> Acc: 97.74% | Loss: 0.0083\n  No improvement.\nEpoch [40/50]\n  Train -> Acc: 97.91% | Loss: 0.0060\n  Val   -> Acc: 97.64% | Loss: 0.0078\n  No improvement.\nEpoch [41/50]\n  Train -> Acc: 97.90% | Loss: 0.0060\n  Val   -> Acc: 97.80% | Loss: 0.0073\n  No improvement.\nEpoch [42/50]\n  Train -> Acc: 97.86% | Loss: 0.0059\n  Val   -> Acc: 97.98% | Loss: 0.0068\n  âœ… Best model saved (state_dict).\nEpoch [43/50]\n  Train -> Acc: 97.96% | Loss: 0.0056\n  Val   -> Acc: 97.92% | Loss: 0.0070\n  No improvement.\nEpoch [44/50]\n  Train -> Acc: 97.95% | Loss: 0.0057\n  Val   -> Acc: 97.92% | Loss: 0.0072\n  No improvement.\nEpoch [45/50]\n  Train -> Acc: 97.96% | Loss: 0.0058\n  Val   -> Acc: 97.88% | Loss: 0.0071\n  No improvement.\nEpoch [46/50]\n  Train -> Acc: 98.05% | Loss: 0.0054\n  Val   -> Acc: 97.63% | Loss: 0.0074\n  No improvement.\nEpoch [47/50]\n  Train -> Acc: 97.95% | Loss: 0.0056\n  Val   -> Acc: 98.02% | Loss: 0.0066\n  âœ… Best model saved (state_dict).\nEpoch [48/50]\n  Train -> Acc: 98.02% | Loss: 0.0054\n  Val   -> Acc: 98.05% | Loss: 0.0069\n  No improvement.\nEpoch [49/50]\n  Train -> Acc: 97.99% | Loss: 0.0055\n  Val   -> Acc: 97.89% | Loss: 0.0076\n  No improvement.\nEpoch [50/50]\n  Train -> Acc: 98.11% | Loss: 0.0052\n  Val   -> Acc: 98.08% | Loss: 0.0073\n  No improvement.\n\n=== Final Test Set Performance ===\nTest Acc: 98.13% | F1: 0.9798 | Sensitivity: 0.9813 | PPV: 0.9806 | Specificity: 0.9265\nðŸ•’ Inference Time on Test Set: 0.34 seconds\n\n=== Model Complexity ===\nðŸ“Š Params: 327.62 k\nðŸ“Š FLOPs: 14.08 MMac\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(CNNTransformerModel(\n   (conv1): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n   (conv2): Conv1d(32, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n   (conv3): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n   (relu): ReLU()\n   (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n   (embedding): Linear(in_features=64, out_features=128, bias=True)\n   (transformer_blocks): ModuleList(\n     (0-1): 2 x TransformerBlock(\n       (attention): MultiheadAttention(\n         (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n       )\n       (feed_forward): Sequential(\n         (0): Linear(in_features=128, out_features=256, bias=True)\n         (1): ReLU()\n         (2): Dropout(p=0.2, inplace=False)\n         (3): Linear(in_features=256, out_features=128, bias=True)\n       )\n       (layernorm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n       (layernorm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n       (dropout): Dropout(p=0.2, inplace=False)\n     )\n   )\n   (fc): Sequential(\n     (0): Linear(in_features=128, out_features=128, bias=True)\n     (1): ReLU()\n     (2): Dropout(p=0.2, inplace=False)\n     (3): Linear(in_features=128, out_features=5, bias=True)\n   )\n ),\n {'train_acc': [87.97249061883034,\n   93.80777427663664,\n   94.75569734450794,\n   95.37544290888171,\n   95.67224089013244,\n   95.97034635147679,\n   96.13508884327236,\n   96.34167069806362,\n   96.3155210961913,\n   96.60447419688035,\n   96.88296745682047,\n   96.90911705869279,\n   96.93526666056509,\n   97.13269615470105,\n   97.05293986899049,\n   97.23990952237752,\n   97.21898984087967,\n   97.21375992050521,\n   97.28697880574768,\n   97.38765477295608,\n   97.4896382202581,\n   97.44387641698155,\n   97.53540002353463,\n   97.51055790175594,\n   97.53670750362826,\n   97.6151563092452,\n   97.61907874952604,\n   97.64522835139834,\n   97.73413699776421,\n   97.7746688806663,\n   97.56939450596865,\n   97.74851927879398,\n   97.74328935841952,\n   97.75505667926205,\n   97.87534484787469,\n   97.8596550867513,\n   97.87142240759384,\n   97.83873540525346,\n   97.77597636075991,\n   97.91064681040231,\n   97.89757200946616,\n   97.86227004693853,\n   97.95771609377248,\n   97.94594877292994,\n   97.96163853405332,\n   98.05446962070002,\n   97.94987121321078,\n   98.02309009845325,\n   97.99171057620647,\n   98.1119987448191],\n  'val_acc': [93.1127585575691,\n   94.48105436573312,\n   94.94325462200256,\n   96.04612850082373,\n   96.17883946549514,\n   96.90646165110745,\n   96.69137836353651,\n   96.74171700530844,\n   96.11477210323997,\n   97.13069741900055,\n   97.28628958447739,\n   97.1993410214168,\n   97.35950942705473,\n   97.43272926963208,\n   97.35493318689365,\n   97.54713527365917,\n   97.24052718286656,\n   97.29086582463847,\n   97.24052718286656,\n   97.73933736042467,\n   97.50594911220941,\n   97.79425224235767,\n   97.66611751784734,\n   96.96137653304045,\n   97.67984623833058,\n   96.98425773384587,\n   97.69357495881384,\n   97.74848984074684,\n   97.82170968332419,\n   97.58374519494784,\n   97.55171151382025,\n   97.73018488010251,\n   97.57001647446458,\n   97.39154310818232,\n   97.61120263591434,\n   97.66154127768625,\n   97.8171334431631,\n   97.73476112026358,\n   97.73933736042467,\n   97.63866007688084,\n   97.80340472267984,\n   97.97730184880102,\n   97.92238696686802,\n   97.92238696686802,\n   97.88120080541827,\n   97.62950759655867,\n   98.02306425041186,\n   98.04594545121728,\n   97.89492952590152,\n   98.08255537250595],\n  'train_loss': [0.05021529328264919,\n   0.02318597900335456,\n   0.018500589044144793,\n   0.015975723203885243,\n   0.0144233463365541,\n   0.013398194873633865,\n   0.012293770915928318,\n   0.011973550597308546,\n   0.01184029612078154,\n   0.011109375262112796,\n   0.0103155424562205,\n   0.00997530341979247,\n   0.009689888621004528,\n   0.009208806349863189,\n   0.009108897684808558,\n   0.008700260851239431,\n   0.008609038839166529,\n   0.008627260159887996,\n   0.008228871065548569,\n   0.00789476621027391,\n   0.007668118548180821,\n   0.007855729132588567,\n   0.007606743378109177,\n   0.007490642507791046,\n   0.007411695084784548,\n   0.007229212474021095,\n   0.007005901427871009,\n   0.0070522161579089715,\n   0.006680160089642009,\n   0.006589859627875621,\n   0.006996726409110076,\n   0.006651535012816113,\n   0.006657853419950893,\n   0.006449529020829021,\n   0.006157739639257308,\n   0.006163258636783011,\n   0.006117613606032663,\n   0.00628676822655881,\n   0.0062457158865467845,\n   0.0059534238152444225,\n   0.0060415857640503095,\n   0.00593529726194847,\n   0.005570933545151582,\n   0.005742018541280666,\n   0.005816164726206883,\n   0.0054473684974914935,\n   0.0056492515422448975,\n   0.005426355959309489,\n   0.005518018697500603,\n   0.005177510214792751],\n  'val_loss': [0.026274602468076506,\n   0.018463181026759205,\n   0.018254662287960712,\n   0.013574780253638999,\n   0.0125419629263904,\n   0.010516319527394243,\n   0.011346413921401427,\n   0.011575838668021367,\n   0.01204560848895177,\n   0.010048786491735658,\n   0.008913272443739425,\n   0.009429577964750168,\n   0.009000598383884964,\n   0.008329302807779689,\n   0.008916507355258828,\n   0.008413944198009258,\n   0.010048053101418616,\n   0.009355184032543623,\n   0.0094647418815855,\n   0.00783425629920495,\n   0.008461881956570286,\n   0.0074522791914396775,\n   0.008556822656615698,\n   0.009573867886289084,\n   0.0075672642587907395,\n   0.009372531946977241,\n   0.007566299108034054,\n   0.007684934513959271,\n   0.007255957642303267,\n   0.008422893873001967,\n   0.007947471318221842,\n   0.00757583363079711,\n   0.0076465249743737414,\n   0.008257767691396786,\n   0.007766449431839742,\n   0.007676516720829041,\n   0.007841302455697013,\n   0.0075344562262285785,\n   0.008292162461391491,\n   0.007784003213494581,\n   0.007347538971276791,\n   0.006750489955792497,\n   0.007009778646970092,\n   0.007213323429834141,\n   0.0070574785812828715,\n   0.00736642881345592,\n   0.00661543470995272,\n   0.006941157374095324,\n   0.0076355744209086075,\n   0.007290870563619993]})"},"metadata":{}}],"execution_count":3},{"id":"e6bbef2b-a6a6-4ac5-a776-aa88c6876037","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}